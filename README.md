# ELMo Embeddings for Medica transcriptions
To convert Optum's Medica speech transcriptions to ELMo embeddings per sentence for clustering.

## Requirements:
 * Python3 (>=3.6 for AllenNLP)
 * AllenNLP
 * TensorFlow
 * NumPy
 * SKLearn (for clustering)
 * Torch (for AllenNLP)
 * SciPy (for SKLearn stop words)

## Install
To install the necessary dependencies:

```bash
apt-get install python3-pip
pip3 install allennlp
pip3 install tensorflow-gpu
pip3 install numpy
pip3 install sklearn
pip3 install torch
# pip3 install scipy
```

Or to run inside a Docker container:
```bash
docker build -t elmo-embeddings .
docker exec -i -t elmo-embeddings /bin/bash
python3.6 main.py
```

## Usage
To generate sentence embeddings, make sure that the `sentences.txt` file is formatted as such:

```bash
<sentence/transcription>
<sentence/transcription>
# and so on...
```

Run `python3 main.py` with the following options:
 * `--mode embed` to embed the sentence file
 * `--mode sif` to enhance sentence embeddings with SIF
 * `--mode tsne` to run t-SNE for visualization
 * `--mode cluster` to cluster embeddings
 * `--mode metadata` to write metadata file
 * `--mode tensorboard` to create TensorBoard files
 * `--mode analyze` to write clustered sentences to files

A couple auxiliary files:
 * Run `sh clean.sh` to convert transcriptions to lower case and remove stop words


## Outputs
An output folder will be created in the current directory containing:
 * `embeddings.npy`: a NumPy array of sentence embeddings (NumPy arrays) in binary format
 * `embeddings_sif.npy`: a NumPy array of sentence embeddings after SIF
 * `embeddings_ts.npy`: a NumPy array of sentence embeddings after t-SNE
 * `db_labels.json`: a list of cluster labels generated by DBSCAN
 * `km_labels.json`: a list of cluster labels generated by KMeans
 * `metadata.tsv`: metadata of sentence labels for visualization

Other nested output folders:
 * `tensorboard`: for TensorBoard output logs
 * `groups`: for clustered sentences
 * `trimmed`: for another copy of embeddings/sentences with specified clusters removed


## Results
On a dataset of 48k transcriptions / 137k sentences, the following process produced relatively defined clusters:
```bash
ELMo -> layer 2 (per word) -> average (per sentence) -> SIF -> KMeans (k=100)
t-SNE (7.5k iterations, for visualization)
```


## TO-DO
 - [x] Preprocess transcriptions
 - [x] Embed each sentence with ELMo
 - [x] Enhance embeddings with SIF
 - [x] Cluster using SKLearn (DBSCAN, KMeans)
 - [x] Use t-SNE to project onto 3D
 - [x] Run in TensorBoard
 - [x] Clean noise from clusters and re-cluster (optional)
 - [ ] Conclusions
