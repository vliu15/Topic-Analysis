{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Timer to compare runtimes.\"\"\"\n",
    "from timeit import default_timer\n",
    "\n",
    "class Timer(object):\n",
    "    def __init__(self):\n",
    "        self._timer = default_timer\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.stop()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.start = self._timer()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer. Calculate the interval in seconds.\"\"\"\n",
    "        self.end = self._timer()\n",
    "        self.interval = self.end - self.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Helper functions for managing NumPy / Pandas inputs.\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_numpy(filename):\n",
    "    \"\"\"Loads NumPy embeddings.\"\"\"\n",
    "    assert os.path.exists(file) and file.endswith(\".npy\"), \"File doesnt exist.\"\n",
    "    return np.load(file)\n",
    "\n",
    "def load_pandas(filename):\n",
    "    \"\"\"Loads NumPy embeddings. Converts to Pandas.\"\"\"\n",
    "    data = load_numpy(file)\n",
    "    return pd.DataFrame({'ft%d'%i: X[i] for i in range(data.shape[0])})\n",
    "\n",
    "def pd_to_np(x):\n",
    "    \"\"\"Converts Pandas to NumPy.\"\"\"\n",
    "    if isinstance(x, pd.DataFrame):\n",
    "        return np.array(x)\n",
    "    print(\"Warning: Input is not a Pandas DataFrame.\")\n",
    "    return x\n",
    "\n",
    "def np_to_pd(x):\n",
    "    \"\"\"Converts NumPy to Pandas.\"\"\"\n",
    "    if isinstance(x, np.ndarray) or isinstance(x, np.array):\n",
    "        return pd.DataFrame({'ft%d'%i: X[i] for i in range(x.shape[0])})\n",
    "    print(\"Warning: Input is not a NumPy array.\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SKLearn KMeans helper function.\"\"\"\n",
    "%%time\n",
    "from sklearn.cluster import KMeans as skKM\n",
    "\n",
    "def sklearn_kmeans(embeddings, params):\n",
    "    \"\"\"Computes SKLearn KMeans.\"\"\"\n",
    "    # cluster with sklearn kmeans\n",
    "    km = skKM(n_clusters=params['n_clusters'],\n",
    "              n_init=parms['n_init'],\n",
    "              max_iter=params['max_iter'],\n",
    "              tol=params['tol'],\n",
    "              precompute_distances=params['precompute_distances'],\n",
    "              verbose=params['verbose'],\n",
    "              random_state=params['random_state'],\n",
    "              copy_x=params['copy_x'],\n",
    "              n_jobs=params['n_jobs'],\n",
    "              algorithm=params['algorithm'])\n",
    "    km.fit(embeddings)\n",
    "    return (km.labels_, km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'cuml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f5aa9b4a732e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKMeans\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcuKM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'cuml'"
     ]
    }
   ],
   "source": [
    "\"\"\"cuML KMeans helper function.\"\"\"\n",
    "%%time\n",
    "import cuml.KMeans as cuKM\n",
    "import cudf\n",
    "\n",
    "def cuml_kmeans(df, params):\n",
    "    \"\"\"Computes cuML KMeans.\"\"\"\n",
    "    # convert pandas input to cudf\n",
    "    embeddings = cudf.from_pandas(df)\n",
    "    \n",
    "    # cluster with cuml kmeans\n",
    "    km = cuKM(n_clusters=params['n_clusters'],\n",
    "              max_iter=params['max_iter'],\n",
    "              tol=params['tol'],\n",
    "              verbose=params['verbose'],\n",
    "              random_state=params['random_state'],\n",
    "              precompute_distances=params['precompute_distances'],\n",
    "              init=params['init'],\n",
    "              n_init=params['n_init'],\n",
    "              algorithm=params['algorithm'],\n",
    "              n_gpus=params['n_gpus'],\n",
    "              gpu_id=params['gpu_id'])\n",
    "    km.fit(df)\n",
    "    return (km.labels_, km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"KMeans wrapper for SKLearn / cuML KMeans.\"\"\"\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def kmeans_wrapper(params):\n",
    "    \"\"\"Computes inertia and silhouette scores. Writes clusters to files.\"\"\"\n",
    "    # ensure each embedding corresponds to a sentence\n",
    "    embeddings = load_numpy(params['emb_file'])\n",
    "    sentences = open(params['sent_file'], 'r').read().splitlines()\n",
    "    assert embeddings.shape[0] == len(sentences), \"Count of sentences and embeddings must match.\"\n",
    "    \n",
    "    # compute sklearn kmeans\n",
    "    print(\"Computing skLearn KMeans...\")\n",
    "    sk_labels, sk_inertia = sklearn_kmeans(embeddings, params['sklearn_kmeans'])\n",
    "    sk_sil = silhouette_score(embeddings, sk_labels)\n",
    "    print(\"Inertia: %.6f \\n 'Silhouette Score: %.6f\\n\" \\\n",
    "          %(sk_inertia, sk_sil))\n",
    "    \n",
    "    # compute cuml kmeans\n",
    "    print(\"Computing cuML KMeans...\")\n",
    "    cu_labels, cu_inertia = cuml_kmeans(np_to_pd(embeddings), params['cuml_kmeans'])\n",
    "    cu_sil = silhouette_score(embeddings, cu_labels)\n",
    "    print(\"Inertia: %.6f \\n 'Silhouette Score: %.6f\\n\" \\\n",
    "          %(cu_inertia, cu_sil))\n",
    "    \n",
    "    # check for valid output directory\n",
    "    out_dir = params['out_dir']\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    elif len(os.listdir(out_dir)) > 0:\n",
    "        print(\"Warning: Non-empty directory. Outputs may be corrupted.\")\n",
    "        \n",
    "    # write clustered sentences to output\n",
    "    for i in range(embeddings.shape[0]):\n",
    "        l = labels[i]\n",
    "        sk_file = 'sk' + str(l) + '.txt'\n",
    "        cu_file = 'cu' + str(l) + '.txt'\n",
    "        with open(os.path.join(out_dir, sk_file), 'a') as fs:\n",
    "            fs.write(sentences[i] + '\\n')\n",
    "        with open(os.path.join(out_dir, cu_file), 'a') as fc:\n",
    "            fc.write(sentences[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Handles user input for files.\"\"\"\n",
    "import argparse\n",
    "\n",
    "def main(params):\n",
    "    \"\"\"Parses command-line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--out_dir', nargs='?', type=str, default=None, help='Output directory for KMeans.')\n",
    "    parser.add_argument('--emb_file', nargs='?', type=str, default=None, help='.npy file of embeddings.')\n",
    "    parser.add_argument('--sent_file', nargs='?', type=str, default=None, help='.txt file of sentences.')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.out_dir == None: params['out_dir'] = os.path.join(os.getcwd(), 'rapids')\n",
    "    else: params['out_dir'] = args.out_dir\n",
    "\n",
    "    if args.emb_file == None: params['emb_file'] = os.path.join(os.getcwd(), 'data', 'medica-s.npy')\n",
    "    else: params['emb_file'] = args.emb_file\n",
    "\n",
    "    if args.sent_file == None: params['sent_file'] = os.path.join(os.getcwd(), 'data', 'medica-s.txt')\n",
    "    else: params['sent_file'] = args.sent_file\n",
    "        \n",
    "    kmeans_wrapper(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parameters for KMeans clustering.\"\"\"\n",
    "# default kmeans parameters\n",
    "params = {\n",
    "    'sklearn_kmeans': {\n",
    "        'n_clusters': 8,\n",
    "        'init': 'kmeans++',\n",
    "        'n_init': 10,\n",
    "        'max_iter': 300,\n",
    "        'tol': 1e-4,\n",
    "        'precompute_distances': 'auto',\n",
    "        'verbose': 0,\n",
    "        'random_state': None,\n",
    "        'copy_x': True,\n",
    "        'n_jobs': None,\n",
    "        'algorithm': 'auto'\n",
    "    },\n",
    "    \n",
    "    'cuml_kmeans': {\n",
    "        'n_clusters': 8,\n",
    "        'max_iter': 300,\n",
    "        'tol': 1e-4,\n",
    "        'verbose': 0,\n",
    "        'random_state': 1,\n",
    "        'precompute_distances': 'auto',\n",
    "        'init': 'kmeans++',\n",
    "        'n_init': 1,\n",
    "        'algorithm': 'auto',\n",
    "        'n_gpus': 1,\n",
    "        'gpu_id': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# run everything!\n",
    "if __name__ == '__main__':\n",
    "    main(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
